{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86c680c-8525-4f9a-b472-9b3e2272d883",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "- 트리 기반의 앙상블 학습에서 가장 각광받고 있는 알고리즘 중 하나\n",
    "- 압도적인 수치의 차이는 아니지만, 분류에 있어서 일반적으로 다른 머신러닝보다 예측성능이 뛰어남\n",
    "- GBM(경사하강법) 기반, 느린 수행시간및 과적합 규제 부재등의 문제를 해결\n",
    "- 병렬 CPU 환경에서 병렬 학습이 가능해 기존 GBM보다 빠르게 학습\n",
    "\n",
    "### 장점\n",
    "- 가지치기\n",
    "- 교차검증 내장\n",
    "- 결측값 자체 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc78fa5-568a-46df-8fe4-65ad1187fd90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "# 버전 확인\n",
    "xgboost.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492a3924-b4d3-43f1-8f1c-c6d837eaa014",
   "metadata": {},
   "source": [
    "### 파이썬 래퍼 XGBoost로 위스콘신 유방암 예측 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac64875-0291-4ace-b344-918905d23adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33            184.6      2019.0   \n",
       "1                 0.05667  ...          23.41            158.8      1956.0   \n",
       "2                 0.05999  ...          25.53            152.5      1709.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "X_features = dataset.data\n",
    "y_label = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data = X_features, columns = dataset.feature_names)\n",
    "cancer_df['target'] = y_label\n",
    "cancer_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee996d87-cf97-4ae7-a5c0-6369bb72f30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "1    357\n",
      "0    212\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target_names)\n",
    "print(cancer_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eefedcc3-db27-455d-a1ff-bafaf67b9a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n"
     ]
    }
   ],
   "source": [
    "# 학습/테스트 데이터 셋 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label,\n",
    "                                                    test_size=0.2, random_state = 156)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f99fa5-e7b2-4d92-9b65-37bf02673e66",
   "metadata": {},
   "source": [
    "**학습과 예측 데이터 셋을 DMatrix로 변환**\n",
    "- DMatrix = XGBoost 전용 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc2dad8-506a-47d3-9515-38a5eeb4ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(data = X_train, label = y_train)\n",
    "dtest = xgb.DMatrix(data = X_test, label = y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11df9ab1-be68-43d8-a0f4-216c0a150cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "params = {\n",
    "    'max_depth' : 3,\n",
    "    'eta' : 0.1, # 학습률\n",
    "    'objective' : 'binary:logistic',  # 손실함수\n",
    "    'eval_metric' : 'logloss'  # 오류 함수 성능 평가 지표\n",
    "}\n",
    "num_rounds = 400  # 400번 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d6f9796-500d-4ee6-a2fd-4217a0cd2d6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.60969\teval-logloss:0.61352\n",
      "[1]\ttrain-logloss:0.54080\teval-logloss:0.54784\n",
      "[2]\ttrain-logloss:0.48375\teval-logloss:0.49425\n",
      "[3]\ttrain-logloss:0.43446\teval-logloss:0.44799\n",
      "[4]\ttrain-logloss:0.39055\teval-logloss:0.40911\n",
      "[5]\ttrain-logloss:0.35414\teval-logloss:0.37498\n",
      "[6]\ttrain-logloss:0.32122\teval-logloss:0.34571\n",
      "[7]\ttrain-logloss:0.29259\teval-logloss:0.32053\n",
      "[8]\ttrain-logloss:0.26747\teval-logloss:0.29721\n",
      "[9]\ttrain-logloss:0.24515\teval-logloss:0.27799\n",
      "[10]\ttrain-logloss:0.22569\teval-logloss:0.26030\n",
      "[11]\ttrain-logloss:0.20794\teval-logloss:0.24604\n",
      "[12]\ttrain-logloss:0.19218\teval-logloss:0.23156\n",
      "[13]\ttrain-logloss:0.17792\teval-logloss:0.22005\n",
      "[14]\ttrain-logloss:0.16522\teval-logloss:0.20857\n",
      "[15]\ttrain-logloss:0.15362\teval-logloss:0.19999\n",
      "[16]\ttrain-logloss:0.14333\teval-logloss:0.19012\n",
      "[17]\ttrain-logloss:0.13398\teval-logloss:0.18182\n",
      "[18]\ttrain-logloss:0.12560\teval-logloss:0.17473\n",
      "[19]\ttrain-logloss:0.11729\teval-logloss:0.16766\n",
      "[20]\ttrain-logloss:0.10969\teval-logloss:0.15820\n",
      "[21]\ttrain-logloss:0.10297\teval-logloss:0.15473\n",
      "[22]\ttrain-logloss:0.09707\teval-logloss:0.14895\n",
      "[23]\ttrain-logloss:0.09143\teval-logloss:0.14331\n",
      "[24]\ttrain-logloss:0.08633\teval-logloss:0.13634\n",
      "[25]\ttrain-logloss:0.08131\teval-logloss:0.13278\n",
      "[26]\ttrain-logloss:0.07686\teval-logloss:0.12791\n",
      "[27]\ttrain-logloss:0.07284\teval-logloss:0.12526\n",
      "[28]\ttrain-logloss:0.06925\teval-logloss:0.11998\n",
      "[29]\ttrain-logloss:0.06555\teval-logloss:0.11641\n",
      "[30]\ttrain-logloss:0.06241\teval-logloss:0.11450\n",
      "[31]\ttrain-logloss:0.05959\teval-logloss:0.11257\n",
      "[32]\ttrain-logloss:0.05710\teval-logloss:0.11154\n",
      "[33]\ttrain-logloss:0.05441\teval-logloss:0.10868\n",
      "[34]\ttrain-logloss:0.05204\teval-logloss:0.10668\n",
      "[35]\ttrain-logloss:0.04975\teval-logloss:0.10421\n",
      "[36]\ttrain-logloss:0.04775\teval-logloss:0.10296\n",
      "[37]\ttrain-logloss:0.04585\teval-logloss:0.10058\n",
      "[38]\ttrain-logloss:0.04401\teval-logloss:0.09868\n",
      "[39]\ttrain-logloss:0.04226\teval-logloss:0.09644\n",
      "[40]\ttrain-logloss:0.04065\teval-logloss:0.09587\n",
      "[41]\ttrain-logloss:0.03913\teval-logloss:0.09424\n",
      "[42]\ttrain-logloss:0.03738\teval-logloss:0.09471\n",
      "[43]\ttrain-logloss:0.03611\teval-logloss:0.09427\n",
      "[44]\ttrain-logloss:0.03494\teval-logloss:0.09389\n",
      "[45]\ttrain-logloss:0.03365\teval-logloss:0.09418\n",
      "[46]\ttrain-logloss:0.03253\teval-logloss:0.09402\n",
      "[47]\ttrain-logloss:0.03148\teval-logloss:0.09236\n",
      "[48]\ttrain-logloss:0.03039\teval-logloss:0.09301\n",
      "[49]\ttrain-logloss:0.02947\teval-logloss:0.09127\n",
      "[50]\ttrain-logloss:0.02855\teval-logloss:0.09005\n",
      "[51]\ttrain-logloss:0.02753\teval-logloss:0.08961\n",
      "[52]\ttrain-logloss:0.02655\teval-logloss:0.08958\n",
      "[53]\ttrain-logloss:0.02568\teval-logloss:0.09070\n",
      "[54]\ttrain-logloss:0.02500\teval-logloss:0.08958\n",
      "[55]\ttrain-logloss:0.02430\teval-logloss:0.09036\n",
      "[56]\ttrain-logloss:0.02357\teval-logloss:0.09159\n",
      "[57]\ttrain-logloss:0.02296\teval-logloss:0.09153\n",
      "[58]\ttrain-logloss:0.02249\teval-logloss:0.09199\n",
      "[59]\ttrain-logloss:0.02185\teval-logloss:0.09195\n",
      "[60]\ttrain-logloss:0.02132\teval-logloss:0.09194\n",
      "[61]\ttrain-logloss:0.02079\teval-logloss:0.09146\n",
      "[62]\ttrain-logloss:0.02022\teval-logloss:0.09031\n",
      "[63]\ttrain-logloss:0.01970\teval-logloss:0.08941\n",
      "[64]\ttrain-logloss:0.01918\teval-logloss:0.08972\n",
      "[65]\ttrain-logloss:0.01872\teval-logloss:0.08974\n",
      "[66]\ttrain-logloss:0.01833\teval-logloss:0.08962\n",
      "[67]\ttrain-logloss:0.01787\teval-logloss:0.08873\n",
      "[68]\ttrain-logloss:0.01760\teval-logloss:0.08862\n",
      "[69]\ttrain-logloss:0.01724\teval-logloss:0.08974\n",
      "[70]\ttrain-logloss:0.01688\teval-logloss:0.08998\n",
      "[71]\ttrain-logloss:0.01664\teval-logloss:0.08978\n",
      "[72]\ttrain-logloss:0.01629\teval-logloss:0.08958\n",
      "[73]\ttrain-logloss:0.01598\teval-logloss:0.08953\n",
      "[74]\ttrain-logloss:0.01566\teval-logloss:0.08875\n",
      "[75]\ttrain-logloss:0.01539\teval-logloss:0.08860\n",
      "[76]\ttrain-logloss:0.01515\teval-logloss:0.08812\n",
      "[77]\ttrain-logloss:0.01488\teval-logloss:0.08840\n",
      "[78]\ttrain-logloss:0.01464\teval-logloss:0.08874\n",
      "[79]\ttrain-logloss:0.01449\teval-logloss:0.08815\n",
      "[80]\ttrain-logloss:0.01418\teval-logloss:0.08758\n",
      "[81]\ttrain-logloss:0.01401\teval-logloss:0.08741\n",
      "[82]\ttrain-logloss:0.01377\teval-logloss:0.08849\n",
      "[83]\ttrain-logloss:0.01357\teval-logloss:0.08858\n",
      "[84]\ttrain-logloss:0.01341\teval-logloss:0.08807\n",
      "[85]\ttrain-logloss:0.01325\teval-logloss:0.08764\n",
      "[86]\ttrain-logloss:0.01311\teval-logloss:0.08742\n",
      "[87]\ttrain-logloss:0.01293\teval-logloss:0.08761\n",
      "[88]\ttrain-logloss:0.01271\teval-logloss:0.08707\n",
      "[89]\ttrain-logloss:0.01254\teval-logloss:0.08727\n",
      "[90]\ttrain-logloss:0.01235\teval-logloss:0.08716\n",
      "[91]\ttrain-logloss:0.01223\teval-logloss:0.08696\n",
      "[92]\ttrain-logloss:0.01206\teval-logloss:0.08717\n",
      "[93]\ttrain-logloss:0.01193\teval-logloss:0.08707\n",
      "[94]\ttrain-logloss:0.01182\teval-logloss:0.08659\n",
      "[95]\ttrain-logloss:0.01165\teval-logloss:0.08612\n",
      "[96]\ttrain-logloss:0.01148\teval-logloss:0.08714\n",
      "[97]\ttrain-logloss:0.01136\teval-logloss:0.08677\n",
      "[98]\ttrain-logloss:0.01124\teval-logloss:0.08669\n",
      "[99]\ttrain-logloss:0.01113\teval-logloss:0.08655\n",
      "[100]\ttrain-logloss:0.01100\teval-logloss:0.08650\n",
      "[101]\ttrain-logloss:0.01085\teval-logloss:0.08641\n",
      "[102]\ttrain-logloss:0.01076\teval-logloss:0.08629\n",
      "[103]\ttrain-logloss:0.01064\teval-logloss:0.08626\n",
      "[104]\ttrain-logloss:0.01050\teval-logloss:0.08683\n",
      "[105]\ttrain-logloss:0.01039\teval-logloss:0.08677\n",
      "[106]\ttrain-logloss:0.01030\teval-logloss:0.08732\n",
      "[107]\ttrain-logloss:0.01020\teval-logloss:0.08730\n",
      "[108]\ttrain-logloss:0.01007\teval-logloss:0.08728\n",
      "[109]\ttrain-logloss:0.01000\teval-logloss:0.08730\n",
      "[110]\ttrain-logloss:0.00991\teval-logloss:0.08729\n",
      "[111]\ttrain-logloss:0.00980\teval-logloss:0.08800\n",
      "[112]\ttrain-logloss:0.00971\teval-logloss:0.08794\n",
      "[113]\ttrain-logloss:0.00963\teval-logloss:0.08784\n",
      "[114]\ttrain-logloss:0.00956\teval-logloss:0.08807\n",
      "[115]\ttrain-logloss:0.00948\teval-logloss:0.08765\n",
      "[116]\ttrain-logloss:0.00942\teval-logloss:0.08730\n",
      "[117]\ttrain-logloss:0.00931\teval-logloss:0.08780\n",
      "[118]\ttrain-logloss:0.00923\teval-logloss:0.08775\n",
      "[119]\ttrain-logloss:0.00915\teval-logloss:0.08768\n",
      "[120]\ttrain-logloss:0.00912\teval-logloss:0.08763\n",
      "[121]\ttrain-logloss:0.00902\teval-logloss:0.08757\n",
      "[122]\ttrain-logloss:0.00897\teval-logloss:0.08755\n",
      "[123]\ttrain-logloss:0.00890\teval-logloss:0.08716\n",
      "[124]\ttrain-logloss:0.00884\teval-logloss:0.08767\n",
      "[125]\ttrain-logloss:0.00880\teval-logloss:0.08774\n",
      "[126]\ttrain-logloss:0.00871\teval-logloss:0.08828\n",
      "[127]\ttrain-logloss:0.00864\teval-logloss:0.08831\n",
      "[128]\ttrain-logloss:0.00861\teval-logloss:0.08827\n",
      "[129]\ttrain-logloss:0.00856\teval-logloss:0.08789\n",
      "[130]\ttrain-logloss:0.00846\teval-logloss:0.08886\n",
      "[131]\ttrain-logloss:0.00842\teval-logloss:0.08868\n",
      "[132]\ttrain-logloss:0.00839\teval-logloss:0.08874\n",
      "[133]\ttrain-logloss:0.00830\teval-logloss:0.08922\n",
      "[134]\ttrain-logloss:0.00827\teval-logloss:0.08918\n",
      "[135]\ttrain-logloss:0.00822\teval-logloss:0.08882\n",
      "[136]\ttrain-logloss:0.00816\teval-logloss:0.08851\n",
      "[137]\ttrain-logloss:0.00808\teval-logloss:0.08848\n",
      "[138]\ttrain-logloss:0.00805\teval-logloss:0.08839\n",
      "[139]\ttrain-logloss:0.00797\teval-logloss:0.08915\n",
      "[140]\ttrain-logloss:0.00795\teval-logloss:0.08911\n",
      "[141]\ttrain-logloss:0.00790\teval-logloss:0.08876\n",
      "[142]\ttrain-logloss:0.00787\teval-logloss:0.08868\n",
      "[143]\ttrain-logloss:0.00785\teval-logloss:0.08839\n",
      "[144]\ttrain-logloss:0.00778\teval-logloss:0.08927\n",
      "[145]\ttrain-logloss:0.00775\teval-logloss:0.08924\n",
      "[146]\ttrain-logloss:0.00773\teval-logloss:0.08914\n",
      "[147]\ttrain-logloss:0.00769\teval-logloss:0.08891\n",
      "[148]\ttrain-logloss:0.00762\teval-logloss:0.08942\n",
      "[149]\ttrain-logloss:0.00760\teval-logloss:0.08939\n",
      "[150]\ttrain-logloss:0.00758\teval-logloss:0.08911\n",
      "[151]\ttrain-logloss:0.00752\teval-logloss:0.08873\n",
      "[152]\ttrain-logloss:0.00750\teval-logloss:0.08872\n",
      "[153]\ttrain-logloss:0.00746\teval-logloss:0.08848\n",
      "[154]\ttrain-logloss:0.00741\teval-logloss:0.08847\n",
      "[155]\ttrain-logloss:0.00739\teval-logloss:0.08854\n",
      "[156]\ttrain-logloss:0.00737\teval-logloss:0.08852\n",
      "[157]\ttrain-logloss:0.00734\teval-logloss:0.08855\n",
      "[158]\ttrain-logloss:0.00732\teval-logloss:0.08828\n",
      "[159]\ttrain-logloss:0.00730\teval-logloss:0.08830\n",
      "[160]\ttrain-logloss:0.00728\teval-logloss:0.08828\n",
      "[161]\ttrain-logloss:0.00726\teval-logloss:0.08801\n",
      "[162]\ttrain-logloss:0.00724\teval-logloss:0.08776\n",
      "[163]\ttrain-logloss:0.00722\teval-logloss:0.08778\n",
      "[164]\ttrain-logloss:0.00720\teval-logloss:0.08778\n",
      "[165]\ttrain-logloss:0.00718\teval-logloss:0.08752\n",
      "[166]\ttrain-logloss:0.00716\teval-logloss:0.08754\n",
      "[167]\ttrain-logloss:0.00714\teval-logloss:0.08764\n",
      "[168]\ttrain-logloss:0.00712\teval-logloss:0.08739\n",
      "[169]\ttrain-logloss:0.00710\teval-logloss:0.08738\n",
      "[170]\ttrain-logloss:0.00708\teval-logloss:0.08730\n",
      "[171]\ttrain-logloss:0.00707\teval-logloss:0.08737\n",
      "[172]\ttrain-logloss:0.00705\teval-logloss:0.08740\n",
      "[173]\ttrain-logloss:0.00703\teval-logloss:0.08739\n",
      "[174]\ttrain-logloss:0.00701\teval-logloss:0.08713\n",
      "[175]\ttrain-logloss:0.00699\teval-logloss:0.08716\n",
      "[176]\ttrain-logloss:0.00697\teval-logloss:0.08696\n",
      "[177]\ttrain-logloss:0.00696\teval-logloss:0.08705\n",
      "[178]\ttrain-logloss:0.00694\teval-logloss:0.08697\n",
      "[179]\ttrain-logloss:0.00692\teval-logloss:0.08697\n",
      "[180]\ttrain-logloss:0.00690\teval-logloss:0.08704\n",
      "[181]\ttrain-logloss:0.00688\teval-logloss:0.08680\n",
      "[182]\ttrain-logloss:0.00687\teval-logloss:0.08683\n",
      "[183]\ttrain-logloss:0.00685\teval-logloss:0.08658\n",
      "[184]\ttrain-logloss:0.00683\teval-logloss:0.08659\n",
      "[185]\ttrain-logloss:0.00681\teval-logloss:0.08661\n",
      "[186]\ttrain-logloss:0.00680\teval-logloss:0.08637\n",
      "[187]\ttrain-logloss:0.00678\teval-logloss:0.08637\n",
      "[188]\ttrain-logloss:0.00676\teval-logloss:0.08630\n",
      "[189]\ttrain-logloss:0.00675\teval-logloss:0.08610\n",
      "[190]\ttrain-logloss:0.00673\teval-logloss:0.08602\n",
      "[191]\ttrain-logloss:0.00671\teval-logloss:0.08605\n",
      "[192]\ttrain-logloss:0.00670\teval-logloss:0.08615\n",
      "[193]\ttrain-logloss:0.00668\teval-logloss:0.08592\n",
      "[194]\ttrain-logloss:0.00667\teval-logloss:0.08592\n",
      "[195]\ttrain-logloss:0.00665\teval-logloss:0.08598\n",
      "[196]\ttrain-logloss:0.00663\teval-logloss:0.08601\n",
      "[197]\ttrain-logloss:0.00662\teval-logloss:0.08592\n",
      "[198]\ttrain-logloss:0.00660\teval-logloss:0.08585\n",
      "[199]\ttrain-logloss:0.00659\teval-logloss:0.08587\n",
      "[200]\ttrain-logloss:0.00657\teval-logloss:0.08589\n",
      "[201]\ttrain-logloss:0.00656\teval-logloss:0.08595\n",
      "[202]\ttrain-logloss:0.00654\teval-logloss:0.08573\n",
      "[203]\ttrain-logloss:0.00653\teval-logloss:0.08573\n",
      "[204]\ttrain-logloss:0.00651\teval-logloss:0.08575\n",
      "[205]\ttrain-logloss:0.00650\teval-logloss:0.08582\n",
      "[206]\ttrain-logloss:0.00648\teval-logloss:0.08584\n",
      "[207]\ttrain-logloss:0.00647\teval-logloss:0.08578\n",
      "[208]\ttrain-logloss:0.00645\teval-logloss:0.08569\n",
      "[209]\ttrain-logloss:0.00644\teval-logloss:0.08571\n",
      "[210]\ttrain-logloss:0.00643\teval-logloss:0.08581\n",
      "[211]\ttrain-logloss:0.00641\teval-logloss:0.08559\n",
      "[212]\ttrain-logloss:0.00640\teval-logloss:0.08580\n",
      "[213]\ttrain-logloss:0.00639\teval-logloss:0.08581\n",
      "[214]\ttrain-logloss:0.00637\teval-logloss:0.08574\n",
      "[215]\ttrain-logloss:0.00636\teval-logloss:0.08566\n",
      "[216]\ttrain-logloss:0.00634\teval-logloss:0.08584\n",
      "[217]\ttrain-logloss:0.00633\teval-logloss:0.08563\n",
      "[218]\ttrain-logloss:0.00632\teval-logloss:0.08573\n",
      "[219]\ttrain-logloss:0.00631\teval-logloss:0.08578\n",
      "[220]\ttrain-logloss:0.00629\teval-logloss:0.08579\n",
      "[221]\ttrain-logloss:0.00628\teval-logloss:0.08582\n",
      "[222]\ttrain-logloss:0.00627\teval-logloss:0.08576\n",
      "[223]\ttrain-logloss:0.00626\teval-logloss:0.08567\n",
      "[224]\ttrain-logloss:0.00624\teval-logloss:0.08586\n",
      "[225]\ttrain-logloss:0.00623\teval-logloss:0.08587\n",
      "[226]\ttrain-logloss:0.00622\teval-logloss:0.08593\n",
      "[227]\ttrain-logloss:0.00621\teval-logloss:0.08595\n",
      "[228]\ttrain-logloss:0.00619\teval-logloss:0.08587\n",
      "[229]\ttrain-logloss:0.00618\teval-logloss:0.08606\n",
      "[230]\ttrain-logloss:0.00617\teval-logloss:0.08600\n",
      "[231]\ttrain-logloss:0.00616\teval-logloss:0.08592\n",
      "[232]\ttrain-logloss:0.00615\teval-logloss:0.08610\n",
      "[233]\ttrain-logloss:0.00613\teval-logloss:0.08611\n",
      "[234]\ttrain-logloss:0.00612\teval-logloss:0.08617\n",
      "[235]\ttrain-logloss:0.00611\teval-logloss:0.08626\n",
      "[236]\ttrain-logloss:0.00610\teval-logloss:0.08629\n",
      "[237]\ttrain-logloss:0.00609\teval-logloss:0.08622\n",
      "[238]\ttrain-logloss:0.00608\teval-logloss:0.08639\n",
      "[239]\ttrain-logloss:0.00607\teval-logloss:0.08634\n",
      "[240]\ttrain-logloss:0.00606\teval-logloss:0.08618\n",
      "[241]\ttrain-logloss:0.00605\teval-logloss:0.08619\n",
      "[242]\ttrain-logloss:0.00604\teval-logloss:0.08625\n",
      "[243]\ttrain-logloss:0.00602\teval-logloss:0.08626\n",
      "[244]\ttrain-logloss:0.00601\teval-logloss:0.08629\n",
      "[245]\ttrain-logloss:0.00600\teval-logloss:0.08622\n",
      "[246]\ttrain-logloss:0.00599\teval-logloss:0.08640\n",
      "[247]\ttrain-logloss:0.00598\teval-logloss:0.08635\n",
      "[248]\ttrain-logloss:0.00597\teval-logloss:0.08628\n",
      "[249]\ttrain-logloss:0.00596\teval-logloss:0.08645\n",
      "[250]\ttrain-logloss:0.00595\teval-logloss:0.08629\n",
      "[251]\ttrain-logloss:0.00594\teval-logloss:0.08631\n",
      "[252]\ttrain-logloss:0.00593\teval-logloss:0.08636\n",
      "[253]\ttrain-logloss:0.00592\teval-logloss:0.08639\n",
      "[254]\ttrain-logloss:0.00591\teval-logloss:0.08649\n",
      "[255]\ttrain-logloss:0.00590\teval-logloss:0.08644\n",
      "[256]\ttrain-logloss:0.00589\teval-logloss:0.08629\n",
      "[257]\ttrain-logloss:0.00588\teval-logloss:0.08646\n",
      "[258]\ttrain-logloss:0.00587\teval-logloss:0.08639\n",
      "[259]\ttrain-logloss:0.00586\teval-logloss:0.08644\n",
      "[260]\ttrain-logloss:0.00585\teval-logloss:0.08646\n",
      "[261]\ttrain-logloss:0.00585\teval-logloss:0.08649\n",
      "[262]\ttrain-logloss:0.00584\teval-logloss:0.08644\n",
      "[263]\ttrain-logloss:0.00583\teval-logloss:0.08647\n",
      "[264]\ttrain-logloss:0.00582\teval-logloss:0.08632\n",
      "[265]\ttrain-logloss:0.00581\teval-logloss:0.08649\n",
      "[266]\ttrain-logloss:0.00580\teval-logloss:0.08654\n",
      "[267]\ttrain-logloss:0.00579\teval-logloss:0.08647\n",
      "[268]\ttrain-logloss:0.00578\teval-logloss:0.08650\n",
      "[269]\ttrain-logloss:0.00577\teval-logloss:0.08652\n",
      "[270]\ttrain-logloss:0.00576\teval-logloss:0.08669\n",
      "[271]\ttrain-logloss:0.00575\teval-logloss:0.08674\n",
      "[272]\ttrain-logloss:0.00575\teval-logloss:0.08683\n",
      "[273]\ttrain-logloss:0.00574\teval-logloss:0.08668\n",
      "[274]\ttrain-logloss:0.00573\teval-logloss:0.08664\n",
      "[275]\ttrain-logloss:0.00572\teval-logloss:0.08650\n",
      "[276]\ttrain-logloss:0.00571\teval-logloss:0.08636\n",
      "[277]\ttrain-logloss:0.00570\teval-logloss:0.08652\n",
      "[278]\ttrain-logloss:0.00570\teval-logloss:0.08657\n",
      "[279]\ttrain-logloss:0.00569\teval-logloss:0.08659\n",
      "[280]\ttrain-logloss:0.00568\teval-logloss:0.08668\n",
      "[281]\ttrain-logloss:0.00567\teval-logloss:0.08664\n",
      "[282]\ttrain-logloss:0.00566\teval-logloss:0.08650\n",
      "[283]\ttrain-logloss:0.00566\teval-logloss:0.08636\n",
      "[284]\ttrain-logloss:0.00565\teval-logloss:0.08640\n",
      "[285]\ttrain-logloss:0.00564\teval-logloss:0.08643\n",
      "[286]\ttrain-logloss:0.00563\teval-logloss:0.08646\n",
      "[287]\ttrain-logloss:0.00562\teval-logloss:0.08650\n",
      "[288]\ttrain-logloss:0.00562\teval-logloss:0.08637\n",
      "[289]\ttrain-logloss:0.00561\teval-logloss:0.08646\n",
      "[290]\ttrain-logloss:0.00560\teval-logloss:0.08645\n",
      "[291]\ttrain-logloss:0.00559\teval-logloss:0.08632\n",
      "[292]\ttrain-logloss:0.00558\teval-logloss:0.08628\n",
      "[293]\ttrain-logloss:0.00558\teval-logloss:0.08615\n",
      "[294]\ttrain-logloss:0.00557\teval-logloss:0.08620\n",
      "[295]\ttrain-logloss:0.00556\teval-logloss:0.08622\n",
      "[296]\ttrain-logloss:0.00556\teval-logloss:0.08631\n",
      "[297]\ttrain-logloss:0.00555\teval-logloss:0.08618\n",
      "[298]\ttrain-logloss:0.00554\teval-logloss:0.08626\n",
      "[299]\ttrain-logloss:0.00553\teval-logloss:0.08613\n",
      "[300]\ttrain-logloss:0.00553\teval-logloss:0.08618\n",
      "[301]\ttrain-logloss:0.00552\teval-logloss:0.08605\n",
      "[302]\ttrain-logloss:0.00551\teval-logloss:0.08602\n",
      "[303]\ttrain-logloss:0.00551\teval-logloss:0.08610\n",
      "[304]\ttrain-logloss:0.00550\teval-logloss:0.08598\n",
      "[305]\ttrain-logloss:0.00549\teval-logloss:0.08606\n",
      "[306]\ttrain-logloss:0.00548\teval-logloss:0.08597\n",
      "[307]\ttrain-logloss:0.00548\teval-logloss:0.08600\n",
      "[308]\ttrain-logloss:0.00547\teval-logloss:0.08600\n",
      "[309]\ttrain-logloss:0.00546\teval-logloss:0.08588\n",
      "[310]\ttrain-logloss:0.00546\teval-logloss:0.08592\n",
      "[311]\ttrain-logloss:0.00545\teval-logloss:0.08595\n"
     ]
    }
   ],
   "source": [
    "wlist = [(dtrain, 'train'), (dtest,'eval')]  # eval 평가용\n",
    "\n",
    "xgb_model = xgb.train(params= params, dtrain=dtrain, num_boost_round=num_rounds,\n",
    "                     early_stopping_rounds=100, # 연속해서 100번에 손실 변화가 없으면 중단\n",
    "                      evals=wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "077d511e-69ac-43a8-88b6-f2afd6e6e0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict() 수행 결과값을 10개만 표시, 예측 확률 값으로 표시\n",
      "[0.934 0.003 0.91  0.094 0.993 1.    1.    0.999 0.997 0.   ]\n",
      "예측값 10개만 표시: [1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# 예측수행 : 예측 확률값 반환  proba랑 비슷\n",
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict() 수행 결과값을 10개만 표시, 예측 확률 값으로 표시')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "preds = [1 if x > 0.5 else 0  for x in pred_probs]\n",
    "print(f'예측값 10개만 표시: {preds[:10]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b4d50d8-3af5-4cb5-8bb9-f6ce9005b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 평가 지표\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "# 수정된 get_clf_eval() 함수 \n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix( y_test, pred)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    precision = precision_score(y_test , pred)\n",
    "    recall = recall_score(y_test , pred)\n",
    "    f1 = f1_score(y_test,pred)\n",
    "    # ROC-AUC 추가 \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    # ROC-AUC print 추가\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f},\\\n",
    "    F1: {3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7338840-ba71-4426-946d-b0e58540944a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차 행렬\n",
      "[[35  2]\n",
      " [ 1 76]]\n",
      "정확도: 0.9737, 정밀도: 0.9744, 재현율: 0.9870,    F1: 0.9806, AUC:0.9951\n"
     ]
    }
   ],
   "source": [
    "get_clf_eval(y_test, preds, pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c21405-b78f-47bf-aa9a-cb33988376f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
